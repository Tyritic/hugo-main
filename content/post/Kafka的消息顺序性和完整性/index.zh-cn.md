---
date : '2025-03-18T19:40:28+08:00'
draft : false
title : 'Kafka的消息顺序性和完整性'
image : ""
categories : ["Kafka"]
tags : ["消息队列"]
description : "Kafka实现顺序消费和避免重复消费"
math : true
---
## 消息顺序性的保证

Kafka 通过分区机制和消息键来保证消息的顺序性。在 Kafka 中，每个 Topic 可以分为多个分区，每个分区内的消息都是有序的。

在生产者端

- 在同一个分区内，消息是有序的。 
- 消息键将相关消息分配到同一分区，可以保证这些消息在同一分区内依然有序。
- 每次添加消息到 Partition(分区) 的时候都会采用尾加法

Kafka默认的分区策略是基于消息键的哈希值

消费者端

消费者在消费消息时，同一个消费者线程只能同时消费一个分区的消息，这样可以保证消费端在处理某个分区内的消息时是按顺序的。如果 Kafka 集群中没有足够的消费者线程，某个消费者线程可能需要同时消费多个分区的消息，但这些分区之间的顺序是无法保证的。

## 消息完整性的保证

### 生产者端的保证

生产者在发送消息时，需要通过消息确认机制来确保消息成功到达。生产者发送消息至 Broker ，需要处理 Broker 的响应，如果 Broker 返回写入失败等错误消息，重试发送。可以配置 `acks` 参数来决定生产者在收到多少个副本的确认后认为消息发送成功。

### 消费者端的保证

消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。在项目开发中通常建议关闭自动提交offset，**每次在真正消费完消息之后再自己手动提交 offset**

自动提交offset会导致以下问题，当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。

### Broker的保证

Broker通过 **多副本机制** 来保证消息不丢失。Kafka 中的每个分区都有多个副本（Replicas），这些副本分布在不同的 Broker 上。当一个 Broker 宕机时，其他持有该分区副本的 Broker 能够接管工作。

Kafka 的副本分为leader副本和follower副本。每个主题（topic）中的分区（partition）会有一个leader副本和多个follower副本。

- leader副本：每个 Kafka 分区都有一个 Leader，负责处理所有的读写请求
- follower副本：定期从领导者副本中拉取数据，保持数据的一致性。

当leader副本宕机时，会在follower副本中选出一个新的领导者，确保数据的连续性和可用性。

## 消息重复消费的处理方案

Kafka中会出现消息重复的情况，根本原因：**服务端侧已经消费的数据没有成功提交 offset** 

严格意义上是无法从根本上解决重复的消息，因为为了保证消息的可靠性会产生重复的消息。只能从业务层面解决重复消息的影响

只有让消费者的处理逻辑具有 **幂等性** ，保证无论同一条消息被消费多少次，结果都是一样的，从而避免因重复消费带来的副作用。